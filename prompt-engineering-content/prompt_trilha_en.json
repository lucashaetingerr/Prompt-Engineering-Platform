[
  {
    "titulo": "1) Foundations: What is Prompt Engineering?",
    "conteudo": "<p>Prompt engineering is the practice of <strong>designing clear instructions</strong> for generative AI systems such as large language models. The main goal is not to memorize “magic prompts”, but to <strong>structure your request</strong> so the model understands the context, the task, and the expected format.</p>\n<p>A good way to think about prompts is as project <em>briefs</em>: you must explain who the audience is, what the goal is, which constraints exist, and how the output will be evaluated. The more concrete this brief is, the lower the chance of vague or off‑topic answers.</p>\n<ul>\n  <li><strong>Context</strong>: who you are, what the scenario is, which data are available.</li>\n  <li><strong>Task</strong>: what exactly the model should produce (explain, rewrite, summarize, classify, plan, etc.).</li>\n  <li><strong>Constraints</strong>: limits on length, style, language, audience, and banned content.</li>\n  <li><strong>Format</strong>: the final structure of the answer (plain text, list, table, JSON).</li>\n</ul>\n<div class=\"tip\"><strong>Rule of thumb:</strong> if a human would be confused by your request, the model probably will be too.</div>\n<p><strong>Prompt – basic well‑structured example</strong></p>\n<pre><code>You are an introductory Computer Science teacher talking to first‑year students.\n\nContext: the students have never programmed before.\nTask: explain what an algorithm is in simple language.\nConstraints: at most 3 paragraphs of up to 80 words each.\nFormat: use a real‑life analogy and a tiny pseudocode example.</code></pre>"
  },
  {
    "titulo": "2) Clear goal and success criteria",
    "conteudo": "<p>Before writing any prompt, define a <strong>goal</strong> and <strong>success criteria</strong>. Instead of asking “improve this text”, ask yourself: <em>improve in what sense?</em> Clarity? More formal tone? Less jargon?</p>\n<p>Having observable success criteria helps you judge whether the answer is good and also guides the model itself. It reduces trial‑and‑error and makes it easier to compare prompt versions.</p>\n<ul>\n  <li><strong>Goal</strong>: describe what you expect to see in the output.</li>\n  <li><strong>Criteria</strong>: verifiable characteristics (length, structure, required elements).</li>\n  <li><strong>Simple metric</strong>: word count, number of bullets, presence of specific fields.</li>\n</ul>\n<div class=\"tip\"><strong>Golden question:</strong> “How will I know, objectively, that this answer is good?” Put that inside the prompt.</div>\n<p><strong>Prompt – example with explicit goal and criteria</strong></p>\n<pre><code>You are a science communicator.\n\nGoal: summarize the article below for a non‑expert reader.\nSuccess criteria:\n- Up to 180 words.\n- Use simple sentences and avoid technical jargon.\n- Highlight exactly 3 key ideas and 1 limitation of the study.\n\nTask: produce a single summary paragraph followed by 4 bullets:\n- 3 bullets with the main ideas.\n- 1 bullet with the main limitation.\n\nOriginal text:\n[TEXT HERE]</code></pre>"
  },
  {
    "titulo": "3) CANI structure: Context–Action–Norms–Inspection",
    "conteudo": "<p>A practical way to organize prompts is to use the <strong>CANI</strong> structure:</p>\n<ul>\n  <li><strong>Context</strong>: who the model is, what the scenario is, and who the audience is.</li>\n  <li><strong>Action</strong>: what must be done (e.g., summarize, explain, list, compare).</li>\n  <li><strong>Norms</strong>: rules for style, tone, format, length, and forbidden elements.</li>\n  <li><strong>Inspection</strong>: how to check whether the answer is adequate; often includes a checklist.</li>\n</ul>\n<p>Separating these four parts helps you <strong>avoid missing important information</strong> and makes the prompt easier to read and maintain.</p>\n<div class=\"tip\">You can literally write the prompt with labels such as “Context:”, “Task:”, “Norms:”, and “Checklist:”. That also helps the model.</div>\n<p><strong>Prompt – example using CANI</strong></p>\n<pre><code>Context:\nYou are a senior security engineer.\nThe audience is a team of junior developers.\n\nAction:\nRewrite the password policy below to make it clearer and more practical.\n\nNorms:\n- Professional but accessible tone.\n- Short sentences, at most 22 words.\n- Organize as a numbered list of steps.\n- Avoid legal jargon.\n\nInspection:\n- At the end, include a checklist with 5 items that developers can mark as done.\n\nOriginal policy:\n[ORIGINAL TEXT HERE]</code></pre>"
  },
  {
    "titulo": "4) Guiding examples (few‑shot)",
    "conteudo": "<p>Language models learn from patterns. By showing <strong>input–output examples</strong> before the real request, you “train” the model on the fly — this is called <em>few‑shot prompting</em>.</p>\n<p>Good examples should be:</p>\n<ul>\n  <li>Simple and representative of the type of answer you want.</li>\n  <li>Consistent with each other (same style, same format).</li>\n  <li>Limited in number (usually 1–3 examples help a lot).</li>\n</ul>\n<div class=\"tip\">You can also show what you <strong>do not</strong> want by labeling “Inadequate answer” vs. “Good answer”.</div>\n<p><strong>Prompt – few‑shot example for study plans</strong></p>\n<pre><code>Example 1\nInput: \"I want to learn Python from scratch in 4 weeks, 1 hour a day.\"\nOutput:\n- Week 1: basic logic, data types, conditionals.\n- Week 2: loops, functions, modules.\n- Week 3: files and error handling.\n- Week 4: small final project.\n\nExample 2\nInput: \"I need to review basic math in 3 weeks.\"\nOutput:\n- Week 1: operations, fractions, percentages.\n- Week 2: simple equations and ratio problems.\n- Week 3: review exercises.\n\nReal task:\nNow create a similar plan for the following request:\n[LEARNER DESCRIPTION HERE]</code></pre>"
  },
  {
    "titulo": "5) Roles and personas",
    "conteudo": "<p>Defining a <strong>role</strong> for the model (persona) helps steer tone, vocabulary, and level of detail. Instead of just saying “explain”, tell the model <em>who</em> is explaining and <em>to whom</em>.</p>\n<ul>\n  <li><strong>Expertise</strong>: the area (history teacher, lawyer, data engineer, etc.).</li>\n  <li><strong>Audience</strong>: children, experts, executives, customers, and so on.</li>\n  <li><strong>Tone</strong>: informal, technical, motivational, neutral, empathetic.</li>\n  <li><strong>Restrictions</strong>: avoid jargon, mention risks, keep examples realistic.</li>\n</ul>\n<div class=\"tip\">Personas are also useful when you want multiple versions of the same answer for different audiences.</div>\n<p><strong>Prompt – example of a well‑specified persona</strong></p>\n<pre><code>Act as a senior data engineer explaining something to a business manager.\n\nContext: the manager is non‑technical but decides on budget.\nTask: explain what a data lake is and how it helps the company.\n\nNorms:\n- Use business analogies (inventory, logistics, reports).\n- Avoid math formulas.\n- Use at most 5 short paragraphs.\n- End with 3 bullets listing practical benefits.</code></pre>"
  },
  {
    "titulo": "6) Output formats (JSON, tables, lists)",
    "conteudo": "<p>When the answer will be consumed by another system (such as a script or tool), it is essential to request a <strong>structured format</strong>. The most common ones are lists, Markdown tables, and JSON.</p>\n<p>When asking for JSON, describe the <strong>schema</strong>: fields, types, and examples. Also say what to do when a value is missing (for example, use <code>null</code>).</p>\n<ul>\n  <li>Avoid explanatory text outside the JSON if it will be parsed by code.</li>\n  <li>Explicitly say: “return only JSON, with no comments”.</li>\n</ul>\n<div class=\"tip\">You can first generate a free‑form draft and then ask the model to reformat it as JSON. This makes iteration easier.</div>\n<p><strong>Prompt – example JSON output for a job posting</strong></p>\n<pre><code>Read the job description below and produce a structured JSON summary.\n\nJSON schema:\n{\n  \"seniority\": \"junior | mid | senior\",\n  \"area\": \"data engineering | data science | ...\",\n  \"main_responsibilities\": [\"string\"],\n  \"main_requirements\": [\"string\"],\n  \"tech_stack\": [\"string\"]\n}\n\nRules:\n- If you cannot identify a field, use an empty array.\n- Do not include any text outside the JSON.\n\nJob description:\n[TEXT HERE]</code></pre>"
  },
  {
    "titulo": "7) Constraints and acceptance criteria",
    "conteudo": "<p>Constraints make it clear <strong>what is allowed and what is forbidden</strong>. This is especially important in production prompts, to avoid very long, off‑topic, or inappropriate answers.</p>\n<p>You can constrain:</p>\n<ul>\n  <li><strong>Length</strong>: limit on words, characters, bullets, or sections.</li>\n  <li><strong>Content</strong>: banned topics, sensitive data, inappropriate language.</li>\n  <li><strong>Style</strong>: avoid clichés, overly long sentences, passive voice, etc.</li>\n</ul>\n<div class=\"tip\">Combine constraints with a mini checklist at the end of the prompt so the model can self‑check whether the rules were followed.</div>\n<p><strong>Prompt – example with clear constraints</strong></p>\n<pre><code>Context: I will use this text on a B2B product landing page.\n\nTask: rewrite the paragraph below to make it more direct and benefit‑oriented.\n\nConstraints:\n- Between 80 and 120 words.\n- Do not use generic expressions like \"revolutionary\", \"innovative\", \"all‑in‑one solution\".\n- Must mention at least 3 concrete, measurable benefits.\n- Tone: confident and professional.\n\nInternal checklist (do not include in the final copy):\n- [ ] Within the word limit?\n- [ ] No clichés?\n- [ ] Three measurable benefits?</code></pre>"
  },
  {
    "titulo": "8) Style, tone, and voice",
    "conteudo": "<p>Style, tone, and voice ensure consistency. When you ask the AI to write on behalf of a company or organization, it is important to say <strong>how</strong> the message should sound.</p>\n<p>A good tone description usually includes:</p>\n<ul>\n  <li>3 to 5 adjectives (for example: direct, warm, technical, playful).</li>\n  <li>A short example sentence that matches that tone.</li>\n  <li>Things to avoid (jargon, slang, emojis, too many metaphors).</li>\n</ul>\n<div class=\"tip\">You can paste real brand examples and ask: “mimic exactly this style, but with the content below”.</div>\n<p><strong>Prompt – example of tone specification</strong></p>\n<pre><code>You are a copywriter for an educational technology company.\n\nDesired tone:\n- Educational, encouraging, and direct.\n- Avoid jokes, emojis, and slang.\n- Use short sentences with concrete examples.\n\nTone example:\n\"Learning to code does not have to be complicated. Start with small daily challenges and track your weekly progress.\"\n\nTask:\nRewrite the welcome text below to match this tone while keeping the same core meaning.\n\nOriginal text:\n[TEXT HERE]</code></pre>"
  },
  {
    "titulo": "9) Information extraction",
    "conteudo": "<p>Extraction prompts turn free text into <strong>structured data</strong>. They are very useful for reading contracts, emails, and reports and producing specific fields (dates, amounts, names, categories).</p>\n<p>For good extraction prompts, you should:</p>\n<ul>\n  <li>Explicitly list the fields to extract.</li>\n  <li>Specify the format (for example, dates as YYYY-MM-DD).</li>\n  <li>Say what to do when a field is missing (use <code>null</code> or an empty string).</li>\n</ul>\n<div class=\"tip\">If the text is long, you can first ask the model to highlight relevant passages before extracting the final fields.</div>\n<p><strong>Prompt – example of JSON extraction</strong></p>\n<pre><code>Extract the following fields from the contract below and return JSON only.\n\nRequired fields:\n- \"start_date\": date in \"YYYY-MM-DD\" format or null.\n- \"end_date\": date in \"YYYY-MM-DD\" format or null.\n- \"termination_fee\": decimal number with no currency symbol or null.\n- \"contracting_party\": name of the contracting company (string).\n\nRules:\n- If you are not sure about a value, use null.\n- Do not include comments or text outside the JSON.\n\nContract:\n[TEXT HERE]</code></pre>"
  },
  {
    "titulo": "10) Rewriting, summarization, and simplification",
    "conteudo": "<p>Rewriting and summarizing text is one of the most common uses for language models. To get good outputs, be explicit about:</p>\n<ul>\n  <li><strong>Who</strong> will read the text (children, general public, experts).</li>\n  <li><strong>How much simplification</strong> you want (e.g., “equivalent to 8th‑grade reading level”).</li>\n  <li><strong>The final shape</strong> of the output (single paragraph, bullets, FAQ, script, etc.).</li>\n</ul>\n<div class=\"tip\">You can first ask for a summary and then request a second version adapted to a different audience, reusing the same base.</div>\n<p><strong>Prompt – example of simplification</strong></p>\n<pre><code>You are a science teacher explaining a topic to 8th‑grade students.\n\nTask: simplify the text below while keeping the scientific ideas correct.\n\nRules:\n- Reading level: 8th grade.\n- Explain any technical term using everyday examples.\n- Output: (1) one summary paragraph and (2) a list of 5 bullets with at most 14 words each.\n\nOriginal text:\n[TEXT HERE]</code></pre>"
  },
  {
    "titulo": "11) Controlled creative generation",
    "conteudo": "<p>Language models are creative, but they need <strong>guardrails</strong>. When asking for ideas, scripts, or creative texts, set clear limits so that answers are not generic or over the top.</p>\n<p>You can restrict:</p>\n<ul>\n  <li>The number of alternatives (e.g., 5 slogans, 3 titles, 2 email variations).</li>\n  <li>The length of each output (words or characters).</li>\n  <li>Forbidden elements (rhymes, clichés, specific words).</li>\n</ul>\n<div class=\"tip\">Ask for a short <em>rationale</em> for each option. This makes comparison and selection easier.</div>\n<p><strong>Prompt – example of controlled creative generation</strong></p>\n<pre><code>Create 5 slogan options for a B2B cloud data analytics product.\n\nRules:\n- Each slogan must have at most 7 words.\n- Avoid rhymes, puns, and clichés like \"revolutionize\" or \"transform your business\".\n- Tone: confident, practical, and professional.\n- After the list, explain in 2 sentences the criteria you used.</code></pre>"
  },
  {
    "titulo": "12) Reasoning and step‑by‑step methods",
    "conteudo": "<p>For complex tasks (analysis, diagnostics, planning), it is useful to ask the model to show its <strong>step‑by‑step reasoning</strong>. This makes the result more transparent and helps you review it.</p>\n<p>A common approach is to separate <strong>reasoning</strong> and <strong>final answer</strong> into different sections.</p>\n<ul>\n  <li>Ask for a limited number of steps (for example, 3–7).</li>\n  <li>After the steps, ask for a short summary with the final recommendation.</li>\n</ul>\n<div class=\"tip\">To avoid overly long responses, you can say that each step must have at most 2 sentences.</div>\n<p><strong>Prompt – example of structured reasoning</strong></p>\n<pre><code>Task: evaluate whether I should prioritize developing a new product feature.\n\nInstructions:\n1) List 3 to 5 numbered reasoning steps considering impact, effort, and risks.\n2) Then write a \"Conclusion\" section with 1 paragraph summarizing your recommendation.\n\nInput:\n[FEATURE DESCRIPTION HERE]</code></pre>"
  },
  {
    "titulo": "13) Iterating and debugging prompts",
    "conteudo": "<p>Prompts can (and should) be <strong>iterated</strong>. Instead of looking for the “perfect sentence” at once, treat your prompt like a small program: test, adjust, and measure the impact.</p>\n<p>A good practice is to keep a small “prompt changelog”, noting what was changed and the effect on the outputs.</p>\n<ul>\n  <li>Change only a few things at a time (1–2 rules or examples).</li>\n  <li>Compare old vs. new outputs using clear success criteria.</li>\n  <li>Keep versions of prompts that work well for future reuse.</li>\n</ul>\n<div class=\"tip\">You can ask the model itself for suggestions on how to improve your prompt, based on examples of unsatisfactory answers.</div>\n<p><strong>Prompt – example of prompt debugging</strong></p>\n<pre><code>You are a prompt engineering specialist.\n\nI have the following prompt (v0.2) and some results I do not like.\n1) Analyze the current prompt.\n2) Point out 3 likely limitations.\n3) Suggest a v0.3 version of the prompt with your improvements.\n\nCurrent prompt:\n[PROMPT HERE]\n\nUnsatisfactory answers:\n[EXAMPLES HERE]</code></pre>"
  },
  {
    "titulo": "14) Quick evaluation (quality and safety)",
    "conteudo": "<p>Besides generating content, language models can help <strong>evaluate</strong> answers: check clarity, format, completeness, and even safety or privacy risks.</p>\n<p>You can ask the model to act as a “validator” applying simple checklists. This is useful to automate part of the review process before responses reach end users.</p>\n<ul>\n  <li>Define objective criteria (format, required fields, appropriate tone).</li>\n  <li>Ask for a rating (e.g., 1–5) or simply “pass/fail”.</li>\n  <li>Request concrete suggestions for fixing issues when something is inadequate.</li>\n</ul>\n<div class=\"tip\">Use a different model (or a second call) to evaluate an answer produced earlier. This reduces bias.</div>\n<p><strong>Prompt – example of quality reviewer</strong></p>\n<pre><code>Act as a content quality reviewer.\n\nTask: evaluate the answer below using these criteria:\n\nCriteria (answer \"yes\" or \"no\"):\n1) Did it follow the requested format?\n2) Did it answer all of the user's questions?\n3) Did it keep a professional and respectful tone?\n4) Did it avoid dangerous or illegal information?\n\nThen produce:\n- A table with the criteria (columns: criterion, met, comment).\n- One final paragraph explaining the main improvement opportunity.\n\nAnswer to review:\n[ANSWER HERE]</code></pre>"
  },
  {
    "titulo": "15) Boundaries and responsible refusals",
    "conteudo": "<p>In many contexts, it is important for the model to be able to say <strong>“no”</strong>. Requests involving illegality, harm, sensitive data, or dangerous advice should be handled with a polite refusal and, when possible, safe alternatives.</p>\n<p>You can configure the prompt to make these limits explicit and to standardize the refusal style.</p>\n<ul>\n  <li>List the types of requests that must be refused.</li>\n  <li>Define a respectful refusal template.</li>\n  <li>Offer alternative resources (educational information, generic guidance).</li>\n</ul>\n<div class=\"tip\">Even when refusing, the tone should remain respectful and helpful, avoiding moral judgment of the user.</div>\n<p><strong>Prompt – example of responsible refusal</strong></p>\n<pre><code>You are a safety-focused assistant.\n\nIf the user's request involves:\n- Illegal actions,\n- Self-harm or severe risk,\n- Violence,\nthen:\n1) Politely refuse to provide the requested instructions.\n2) Briefly explain why you cannot help.\n3) When appropriate, offer general educational resources or safe guidance instead.\n\nOtherwise, answer normally, following prompt engineering best practices.</code></pre>"
  },
  {
    "titulo": "16) Orchestration with context (RAG) and tools",
    "conteudo": "<p>In more advanced applications, the model receives <strong>external context</strong> (documents, knowledge bases) or interacts with <strong>tools</strong> (code, APIs, databases). This is often called RAG (Retrieval‑Augmented Generation).</p>\n<p>In these scenarios, the prompt should clearly state:</p>\n<ul>\n  <li>That the model must rely only on the provided context.</li>\n  <li>How to cite sources (for example, document IDs or snippet IDs).</li>\n  <li>When to call an external tool (calculation, search, code execution).</li>\n</ul>\n<div class=\"tip\">Whenever possible, ask the model to point to the specific context snippets that support its answer. This increases transparency and trust.</div>\n<p><strong>Prompt – example with external context</strong></p>\n<pre><code>You will receive a set of numbered excerpts from an internal knowledge base.\n\nRules:\n- Answer using only information from these excerpts.\n- When stating a fact, mention in parentheses the IDs of the excerpts used.\n- If the question cannot be answered with the provided material, clearly say\n  \"I do not know based on the provided context\".\n\nContext:\n[EXCERPTS HERE]\n\nUser question:\n[QUESTION HERE]</code></pre>"
  }
]